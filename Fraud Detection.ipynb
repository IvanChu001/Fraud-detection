{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fOwnoGbGtYY",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nYbafDMkGT2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "673660f1-16b3-4071-eeda-a12de8f3bfe8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2aa410b1e5da>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/SDSC3002/Project/creditcard.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mstart_time_now\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \"\"\"\n\u001b[1;32m   1337\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "path='/content/drive/MyDrive/Colab Notebooks//Project/creditcard.csv'\n",
        "df = pd.read_csv(path)\n",
        "start_time_now = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5nNYgATdoVi",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew\n",
        "from scipy.special import boxcox1p\n",
        "from scipy.stats import boxcox_normmax\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sklearn\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu0N3UzJKGYr"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT9CNbSvK_iM"
      },
      "outputs": [],
      "source": [
        " df['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAzoOXSbMMG-"
      },
      "outputs": [],
      "source": [
        "print(df.groupby('Class')['Class'].count()/df['Class'].count()*100)\n",
        "(df.groupby('Class')['Class'].count()/df['Class'].count()*100).plot.pie()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O-QhucMM5Qa"
      },
      "outputs": [],
      "source": [
        "classes=df['Class'].value_counts()\n",
        "nomral_share=classes[0]/df['Class'].count()*100\n",
        "fraud_share=classes[1]/df['Class'].count()*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hIXSg7FL4O2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwa9A7JMpwIe"
      },
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(7,5))\n",
        "#sns.countplot(df['Class'])\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9TjfHb5qNBj"
      },
      "outputs": [],
      "source": [
        "#FIND THE CORELATION\n",
        "#corr\n",
        "corr=df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9dk2WAXqw7n",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(24,18))\n",
        "\n",
        "sns.heatmap(corr,cmap='coolwarm', annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Pu0n_LrpjE"
      },
      "source": [
        "Find the distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78-OE_JKrwiE"
      },
      "outputs": [],
      "source": [
        "Delta_Time = pd.to_timedelta(df['Time'], unit='s')\n",
        "\n",
        "df['Time_Day']=(Delta_Time.dt.components.days).astype(int)\n",
        "df['Time_Hour']=(Delta_Time.dt.components.hours).astype(int)\n",
        "df['Time_Min']=(Delta_Time.dt.components.minutes).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O_x1cettABh"
      },
      "outputs": [],
      "source": [
        "df.drop('Time',axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSKZf6L0siCB"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.drop(['Time_Day','Time_Min'],axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvXvy_OV2Bvf"
      },
      "outputs": [],
      "source": [
        "not_frauds=df.query('Class == 0')\n",
        "frauds=df.query('Class == 1')\n",
        "balanced_df= pd.concat([frauds,not_frauds.sample(len(frauds)+100000,random_state=40)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MUG1En8tBWk"
      },
      "outputs": [],
      "source": [
        "y=balanced_df['Class']\n",
        "X=balanced_df.drop('Class',axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEi5UCG1tYPo"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(X,y, random_state=100, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WkOvVixt7Ww"
      },
      "outputs": [],
      "source": [
        "cols= list(X.columns.values)\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnBGw3kjudwT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from re import sub\n",
        "\n",
        "normal_records = df.Class == 0\n",
        "fraud_records = df.Class == 1\n",
        "\n",
        "plt.figure(figsize=(20, 60))\n",
        "for n, col in enumerate(cols):\n",
        "    plt.subplot(10, 3, n+1)\n",
        "    sns.distplot(X[col][normal_records], color='green')\n",
        "    sns.distplot(X[col][fraud_records], color='red')\n",
        "    plt.title(col, fontsize=17)\n",
        "\n",
        "    # Set legend\n",
        "    plt.legend(labels=['Normal', 'Fraud'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSVxmUHGfiFi"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define flierprops\n",
        "flierprops = dict(marker='x', markerfacecolor='red', markersize=6, linestyle='none')\n",
        "\n",
        "# Iterate over the range\n",
        "for i in range(10):\n",
        "    sns.boxplot(x=df['Class'], y=df.columns[i], data=df, flierprops=flierprops)\n",
        "    plt.title(f'Boxplot of {df.columns[i]} by y')\n",
        "    plt.xlabel('y')\n",
        "    plt.ylabel(df.columns[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "pca_2 = PCA(n_components=2)\n",
        "X_train_pca_2_fitted = pca_2.fit_transform(X_train_scaled)\n",
        "X_train_pca_2 = pca_2.transform(X_train_scaled)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train_pca_2[:, 0], X_train_pca_2[:, 1], marker='x', c=y_train, cmap='viridis', alpha=0.5)\n",
        "plt.title('Feature Space with 2 Principal Components')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar(label='Class (y)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q923x1GzsyXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca_2 = pd.DataFrame(X_train_pca_2, columns=['PC1', 'PC2'])\n",
        "df_pca_2['y'] = y_train.values\n",
        "\n",
        "plt.figure(figsize=(4, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x='y', y='PC1', data=df_pca_2, flierprops={\"marker\": \"x\"})\n",
        "plt.title('PC1 by Class')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='y', y='PC2', data=df_pca_2, flierprops={\"marker\": \"x\"})\n",
        "plt.title('PC2 by Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iHDQEg1QsyPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loadings = pca_2.components_.T\n",
        "num_features = loadings.shape[0]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(num_features):\n",
        "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.075)\n",
        "    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, X_train.columns[i], color='g', ha='center', va='center')\n",
        "\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Loadings for PC1 and PC2')\n",
        "plt.axhline(0, color='b', linestyle='--')\n",
        "plt.axvline(0, color='b', linestyle='--')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ifcyDc3qtlJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-A6QUuGywUo"
      },
      "outputs": [],
      "source": [
        "pca = PCA() #Principal component analysis\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "variance = pca.explained_variance_ratio_\n",
        "\n",
        "cumulative_variance = variance.cumsum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='-')\n",
        "plt.title('Cumulative Variance Explained by Each Principal Component')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Explained Variance')\n",
        "plt.axhline(y=0.99, color='g', linestyle='--', label='99% Explained Variance')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V0BPvX8OtzR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnTzYBU8G7sd"
      },
      "source": [
        "#Model Building\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Results= pd.DataFrame(columns=['Methodology','Model','Accuracy','roc_value','threshold'])\n",
        "\n",
        "def Plot_confusion_matrix(y_test,pred_test):\n",
        "  cm=confusion_matrix(y_test,pred_test)\n",
        "  plt.clf()\n",
        "  plt.imshow(cm,interpolation='nearest',cmap=plt.cm.Accent)\n",
        "  categoryNames=['Not-Fraudalent','Fraudalent']\n",
        "  plt.title('')\n",
        "\n",
        "  plt.title('Confusion Matrix- Test Data')\n",
        "  plt.ylabel(\"True Label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "  ticks = np. arange(len(categoryNames) )\n",
        "  plt.xticks(ticks, categoryNames, rotation=45)\n",
        "  plt.yticks(ticks, categoryNames)\n",
        "  s = [['TN',\"FP\"],['FN',\"TP\"]]\n",
        "\n",
        "\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      plt.text(j,i,str(s[i][j])+'='+str(cm[i][j]),fontsize=12)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "GSKj4nZ5tq2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkNAGZKdG_dm"
      },
      "source": [
        "##LogisticModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEs9OSxU3YWS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def buildAndRunLogisticModels(df_Results,Methodology, X_train, y_train, X_test, y_test):\n",
        "\n",
        "  from sklearn import linear_model\n",
        "  from sklearn.model_selection import KFold\n",
        "\n",
        "  num_C = list(np.power(10.0, np.arange(-10,10)))\n",
        "  cv_num = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "  searchCV_l2 = linear_model.LogisticRegressionCV(Cs=num_C, penalty='l2',\n",
        "                                                  scoring='roc_auc',cv=cv_num,random_state=42,max_iter=10000,\n",
        "                                                  fit_intercept=True,solver='newton-cg',tol=10)\n",
        "\n",
        "  searchCV_l1 = linear_model.LogisticRegressionCV(Cs=num_C, penalty='l1',\n",
        "                                                  scoring='roc_auc',cv=cv_num,random_state=42,max_iter=10000,\n",
        "                                                  fit_intercept=True,solver='liblinear',tol=10)\n",
        "\n",
        "\n",
        "\n",
        "  searchCV_l1.fit(X_train,y_train)\n",
        "  searchCV_l2.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  print ('Max auc_roc for l1:', searchCV_l1.scores_[1].mean (axis=0).max())\n",
        "  print ('Max auc_roc for l2:', searchCV_l2.scores_[1].mean (axis=0).max())\n",
        "  print(\"Parameters for l1 regularisations\")\n",
        "  print(searchCV_l1.coef_)\n",
        "  print(searchCV_l1. intercept_)\n",
        "  print(searchCV_l1. scores_)\n",
        "\n",
        "  print(\"Parameters for l2 regularisations\")\n",
        "  print(searchCV_l2. coef_)\n",
        "  print(searchCV_l2. intercept_)\n",
        "  print (searchCV_l2. scores_)\n",
        "  #find predicted vallues\n",
        "  y_pred_l1 = searchCV_l1.predict(X_test)\n",
        "  y_pred_l2 = searchCV_l2.predict(X_test)\n",
        "\n",
        "\n",
        "  #Find predicted probabilities\n",
        "  y_pred_probs_l1 = searchCV_l1.predict_proba(X_test)[:,1]\n",
        "  y_pred_probs_l2 = searchCV_l2.predict_proba(X_test)[:,1]\n",
        "\n",
        "  Accuracy_l2 = metrics.accuracy_score(y_pred=y_pred_l2, y_true=y_test)\n",
        "  Accuracy_l1 = metrics.accuracy_score(y_pred=y_pred_l1, y_true=y_test)\n",
        "\n",
        "  print(\"Accuarcy of Logistic model with l2 regulaription: {0}\". format(Accuracy_l2))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_l2)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_l2))\n",
        "\n",
        "  print(\"Accuarcy of Logistic model with l1 regularisation : {0}\".format(Accuracy_l1))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_l1)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_l1))\n",
        "\n",
        "  l2_roc_value = roc_auc_score(y_test, y_pred_probs_l2)\n",
        "  print('l2 roc_value: {0}'.format(l2_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l2)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"l2 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\", '{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  new_row =   pd.DataFrame({'Methodology':Methodology,\n",
        "                                               'Model':'Logistic Regression with L2 Regularisation',\n",
        "                                               'Accuracy': Accuracy_l2, 'roc_value': l2_roc_value,\n",
        "                                               'threshold': threshold},index=[0])\n",
        "\n",
        "  df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "\n",
        "  l1_roc_value = roc_auc_score(y_test, y_pred_probs_l1)\n",
        "  print(\"l1 roc_value:{0}\".format(l1_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l1)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"l1 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\", '{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr, label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  new_row =  pd.DataFrame({'Methodology':Methodology,\n",
        "                                               'Model':'Logistic Regression with L1 Regularisation',\n",
        "                                               'Accuracy': Accuracy_l1, 'roc_value': l1_roc_value,\n",
        "                                               'threshold': threshold},index=[0])\n",
        "\n",
        "  df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "\n",
        "  return df_Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO3av1zNHEAN"
      },
      "source": [
        "##KNNModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2wwelBTjQi-"
      },
      "outputs": [],
      "source": [
        "df_Results=pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTydXIhB7m44"
      },
      "outputs": [],
      "source": [
        "def buildAndRunKNNModels(df_Results,Methodology, X_train, y_train, X_test, y_test):\n",
        "\n",
        "\n",
        "  knn = KNeighborsClassifier(n_neighbors=5, n_jobs=16)\n",
        "  knn.fit(X_train,y_train)\n",
        "  score=knn.score(X_test,y_test)\n",
        "  print('model score',score)\n",
        "\n",
        "  y_pred=knn.predict(X_test)\n",
        "  knn_accuracy=metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "  #print(y_pred)\n",
        "  print(\"confusion_matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "  knn_probs = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate roc auc\n",
        "  knn_roc_value = roc_auc_score(y_test, knn_probs)\n",
        "  print(\"KNN roc_value: {0}\" .format(knn_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, knn_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print (\"KNN threshold: {0}\",format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print('ROC for the test dataset','{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr, tpr, label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  new_row = pd.DataFrame({'Methodology': Methodology,\n",
        "                            'Model': 'KNN Model',\n",
        "                            'Accuracy': score,\n",
        "                            'roc_value': knn_roc_value,\n",
        "                            'threshold': threshold}, index=[0])\n",
        "\n",
        "  df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "  return df_Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsgsdJmSHIsv"
      },
      "source": [
        "##TreeModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2cF0tdDREvj"
      },
      "outputs": [],
      "source": [
        "def buildAndRunTreeModels(df_Results, Methodology, X_train,y_train, X_test, y_test ):\n",
        "#Evaluate Decision Tree model with 'gini' & 'entropy'\n",
        "  criteria = ['gini', 'entropy']\n",
        "  scores = {}\n",
        "\n",
        "\n",
        "  for c in criteria:\n",
        "    dt = DecisionTreeClassifier (criterion = c, random_state=42)\n",
        "    dt.fit(X_train, y_train)\n",
        "    y_pred = dt.predict(X_test)\n",
        "    test_score = dt.score(X_test, y_test)\n",
        "    tree_preds = dt.predict_proba(X_test)[:, 1]\n",
        "    tree_roc_value = roc_auc_score(y_test, tree_preds)\n",
        "    scores = test_score\n",
        "    print(c + \" score: {0}\".format(test_score))\n",
        "    print(\"Confusion Matrix\")\n",
        "    Plot_confusion_matrix(y_test, y_pred)\n",
        "    print(\"classification Report\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(c + \" tree_roc_value: {0}\" , format(tree_roc_value))\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, tree_preds)\n",
        "    threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "    print(\"Tree threshold: {0}\".format(threshold))\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "    plt.plot(fpr, tpr, label=\"Test, auc=\"+str(roc_auc))\n",
        "    plt.legend (loc=4)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    new_row =  pd.DataFrame({'Methodology':Methodology,\n",
        "                                               'Model':'Tree Model with {0}criteria'.format(c),\n",
        "                                               'Accuracy': scores, 'roc_value': tree_roc_value,\n",
        "                                               'threshold': threshold},index=[0])\n",
        "\n",
        "\n",
        "\n",
        "    df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "    return df_Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9XelDdEHLON"
      },
      "source": [
        "##RandomForestModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGSGk5y_TrN-"
      },
      "outputs": [],
      "source": [
        "def buildAndRunRandomForestModels(df_Results, Methodology, X_train,y_train, X_test, y_test ):\n",
        "#Evaluate Random Forest model\n",
        "# Create the model with 100 trees\n",
        "\n",
        "  RF_model = RandomForestClassifier(n_estimators=100,\n",
        "  bootstrap = True,\n",
        "  max_features = 'sqrt', random_state=42)\n",
        "\n",
        "  # Fit on training data\n",
        "  RF_model.fit(X_train, y_train)\n",
        "  RF_test_score = RF_model.score(X_test, y_test)\n",
        "  RF_model.predict(X_test)\n",
        "\n",
        "  print('Model Accuracy: {0}'. format(RF_test_score))\n",
        "\n",
        "  # Actual class predictions\n",
        "  rf_predictions = RF_model.predict(X_test)\n",
        "\n",
        "  print (\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, rf_predictions)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, rf_predictions))\n",
        "\n",
        "  # Probabilities for each class\n",
        "  rf_probs = RF_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate roc auc\n",
        "  roc_value = roc_auc_score(y_test, rf_probs)\n",
        "\n",
        "\n",
        "  print (\"Random Forest roc_value: {0}\" .format(roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, rf_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print (\"Random Forest threshold: {0}\". format(threshold))\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\", '{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr, tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  new_row =  pd.DataFrame({'Methodology':Methodology,\n",
        "                                               'Model':'Random Forest',\n",
        "                                               'Accuracy': RF_test_score, 'roc_value': roc_value,\n",
        "                                               'threshold': threshold},index=[0])\n",
        "  df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "  return df_Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyIgtti7HM--"
      },
      "source": [
        "##XGBoostModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHMei-lrWMOM"
      },
      "outputs": [],
      "source": [
        "def buildAndRunXGBoostModels(df_Results, Methodology,X_train,y_train, X_test, y_test ):\n",
        "#EvaLuate XGboost moded\n",
        "  XGBmodel = XGBClassifier(random_state=42)\n",
        "  XGBmodel.fit(X_train, y_train)\n",
        "  y_pred = XGBmodel.predict(X_test)\n",
        "\n",
        "  XGB_test_score = XGBmodel.score(X_test, y_test)\n",
        "  print('Model Accuracy: {0}'.format(XGB_test_score))\n",
        "\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  # Probabilities for each class\n",
        "  XGB_probs = XGBmodel.predict_proba(X_test)[:, 1]\n",
        "  # Calculate roc auc\n",
        "  XGB_roc_value = roc_auc_score(y_test, XGB_probs)\n",
        "\n",
        "  print(\"Xboost roc_value: {0}\".format(XGB_roc_value) )\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, XGB_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"XBoost threshold: {0}\". format(threshold))\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\", '{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show( )\n",
        "\n",
        "  new_row =  pd.DataFrame({'Methodology':Methodology,\n",
        "                                               'Model':'XGB boost Model',\n",
        "                                               'Accuracy': XGB_test_score, 'roc_value': XGB_roc_value,\n",
        "                                               'threshold': threshold},index=[0])\n",
        "  df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "\n",
        "  return df_Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6rV1hUHQne"
      },
      "source": [
        "##SVMModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wsja9P5XNAx"
      },
      "outputs": [],
      "source": [
        "def buildAndRunSVMModels (df_Results, Methodology, X_train,y_train,X_test, y_test):\n",
        "\n",
        "#Evaluate SVM model with sigmoid kernel model\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "\n",
        "  clf = SVC(kernel='sigmoid', random_state=42)\n",
        "  clf.fit (X_train,y_train)\n",
        "  y_pred_SVM = clf.predict(X_test)\n",
        "  SVM_Score = accuracy_score(y_test,y_pred_SVM)\n",
        "  print(\"accuracy_score: {0}\".format(SVM_Score))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_SVM)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_SVM))\n",
        "\n",
        "  # Run classifier\n",
        "  classifier = SVC(kernel='sigmoid' , probability=True)\n",
        "  svm_probs = classifier.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate roc auc\n",
        "  roc_value = roc_auc_score(y_test, svm_probs)\n",
        "\n",
        "  print(\"SVM roc_value: {0}\".format(roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, svm_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"SVM threshold: {0}\".format(threshold))\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\", '{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr, tpr, label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt. legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  new_row =  pd.DataFrame({'Methodology':Methodology,\n",
        "                                               'Model':'SVM Model',\n",
        "                                               'Accuracy': SVM_Score, 'roc_value': roc_value,\n",
        "                                               'threshold': threshold},index=[0])\n",
        "  df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "  return df_Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLCfY86EP5xV"
      },
      "source": [
        "#1.Perform Cross validation with RepeatedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfA5JyFa9hD5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "rkf= RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
        "\n",
        "for train_index, test_index in rkf.split(X,y):\n",
        "  print('Train:', train_index, 'Test:', test_index)\n",
        "  X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s1tt0B8A933",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "print (\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UE4X8bsCuAR",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run KNN Model\n",
        "print (\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZpcmnd9CvDt",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPPqYx3rEu_H"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run RF Model\n",
        "print (\"RF Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moQQzQf0E6zS",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run XGB Model\n",
        "print (\"XGB Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU9SnCDOFMIi",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Run SVM Model\n",
        "print (\"SVM Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVj7PXaAQDE5"
      },
      "source": [
        "#2.Perform Cross validation with StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoWHun2JQAok"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "rkf= StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for train_index, test_index in rkf.split(X,y):\n",
        "  print('Train:', train_index, 'Test:', test_index)\n",
        "  X_train_SKF_cv, X_test_SKF_cv = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train_SKF_cv, y_test_SKF_cv = y.iloc[train_index], y.iloc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxZVtA_yQFDN"
      },
      "outputs": [],
      "source": [
        "print (\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, \"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d69Rv5aRQI9Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, \"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TripIYzDQJri"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, \"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baUGDwRPQKdb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run RF Model\n",
        "print (\"RF Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, \"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im3KngdYQLLP"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run XGB Model\n",
        "print (\"XGB Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, \"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7RCovhgQMBE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run SVM Model\n",
        "print (\"SVM Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results, \"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIPHi1pjIWMF"
      },
      "source": [
        "#Model building with balancing Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeLUvFULIhJo"
      },
      "source": [
        "##3.Oversampling with RandomOverSampler with StratifiedKFold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWohvr_efDd1"
      },
      "outputs": [],
      "source": [
        "X=X.values\n",
        "y=y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1c8SNWZhzVU"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqKb1AEVcn74"
      },
      "outputs": [],
      "source": [
        "\n",
        "ros = RandomOverSampler()\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    ROS = RandomOverSampler(sampling_strategy=0.5)\n",
        "    X_over, y_over = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Proceed with model training and evaluation using the oversampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1C-DS0ejRj8"
      },
      "outputs": [],
      "source": [
        "Data_Imbalance_Handiling = 'Random Oversampling with StratifiedKFold CV'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXKNPCuwiEtK"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, Data_Imbalance_Handiling, X_over,y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwubg017iGMI"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results, Data_Imbalance_Handiling, X_over,y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89IBJJDGiD_b"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, Data_Imbalance_Handiling, X_over,y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRhXM7kilqTQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run RF Model\n",
        "print (\"RF Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, Data_Imbalance_Handiling, X_over,y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJgNlenUiGqX"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, Data_Imbalance_Handiling, X_over,y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsfK7bhXiHoD"
      },
      "outputs": [],
      "source": [
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results, Data_Imbalance_Handiling, X_over,y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-vBvRHcIuPI"
      },
      "source": [
        "##Oversampling with SMOTE Oversampling\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV1nzyxdodmi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn import over_sampling\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
        "\n",
        "  X_train = X[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test = X[test_index]\n",
        "  y_test = y[test_index]\n",
        "  SMOTE = over_sampling.SMOTE(random_state=0)\n",
        "  X_train_Smote, y_train_Smote= SMOTE.fit_resample(X_train, y_train)\n",
        "\n",
        "X_train_Smote = pd.DataFrame(data=X_train_Smote,columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oDQgbOppj1x"
      },
      "outputs": [],
      "source": [
        "Data_Imbalance_Handiling='Smote Oversampling with StratifiedKFold CV'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za-svOL9pKHP"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, Data_Imbalance_Handiling, X_train_Smote,y_train_Smote, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTX52FmZpfjO"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results, Data_Imbalance_Handiling, X_train_Smote,y_train_Smote, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOeXzHdopgCS"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, Data_Imbalance_Handiling, X_train_Smote,y_train_Smote, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2vI2URjlxgw"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run RF Model\n",
        "print (\"RF Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, Data_Imbalance_Handiling, X_train_Smote,y_train_Smote, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWDc4HARpgsw"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, Data_Imbalance_Handiling, X_train_Smote,y_train_Smote, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIXhO_pWphNz"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results, Data_Imbalance_Handiling, X_train_Smote,y_train_Smote, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuR_ZFeLI70Y"
      },
      "source": [
        "##Oversampling with ADASYN Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIa5wu1sqFWs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn import over_sampling\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
        "\n",
        "  X_train = X[train_index]\n",
        "  y_train = y[train_index]\n",
        "  X_test = X[test_index]\n",
        "  y_test = y[test_index]\n",
        "  ADASYN = over_sampling.ADASYN(random_state=0)\n",
        "  X_train_ADASYN, y_train_ADASYN= ADASYN.fit_resample(X_train, y_train)\n",
        "\n",
        "X_train_ADASYN = pd.DataFrame(data=X_train_Smote,columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQKg5YWBflVg"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ada = ADASYN(random_state=42)\n",
        "X_train_ADASYN, y_train_ADASYN = ada.fit_resample(X, y)\n",
        "X_over.shape,y_over.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdA7aUnpr_QN"
      },
      "outputs": [],
      "source": [
        "Data_Imbalance_Handiling='ADASYN Oversampling with StratifiedKFold CV'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF4SSarHsKPD"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN,y_train_ADASYN, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVpfwTSlsRB-"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN,y_train_ADASYN, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYASLU0psRzT"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN,y_train_ADASYN, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIZmmiCikdG8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Run RF Model\n",
        "print (\"RF Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN,y_train_ADASYN, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SjKI3HNsSFI"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN,y_train_ADASYN, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZmgfP6XsSYk"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN,y_train_ADASYN, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Results"
      ],
      "metadata": {
        "id": "EiWyaFVfo3Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nufFrtbKkLDo"
      },
      "outputs": [],
      "source": [
        "df_Results_2=df_Results.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLlqT7EStRwg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ2_yAh7h-KJ"
      },
      "source": [
        "#Demonstrate by specific case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cajQNKyxiyTv"
      },
      "outputs": [],
      "source": [
        "df_Results.to_csv('df_Results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-Q2Ope3Nea2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def buildAndRunKNNModels_results(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=16)\n",
        "    knn.fit(X_train, y_train)\n",
        "    score = knn.score(X_test, y_test)\n",
        "    print('Model score:', score)\n",
        "\n",
        "    y_pred = knn.predict(X_test)\n",
        "    knn_accuracy = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    knn_probs = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate roc auc\n",
        "    knn_roc_value = roc_auc_score(y_test, knn_probs)\n",
        "    print(\"KNN roc_value:\", knn_roc_value)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, knn_probs)\n",
        "    threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "    print (\"KNN threshold:\", threshold)\n",
        "\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    print('ROC for the test dataset:', '{:.1%}'.format(roc_auc))\n",
        "    plt.plot(fpr, tpr, label=\"Test, auc=\" + str(roc_auc))\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "\n",
        "    predictions_list = []  # Initialize an empty list for predictions\n",
        "    predictions_df = pd.DataFrame({'Predicted': y_pred})\n",
        "\n",
        "    # Append predictions_df to predictions_list\n",
        "    predictions_list.append(predictions_df)\n",
        "\n",
        "    # Concatenate all DataFrames in predictions_list\n",
        "    df_Predictions = pd.concat(predictions_list, ignore_index=True)\n",
        "\n",
        "    return df_Predictions\n",
        "\n",
        "df_Predictions=pd.DataFrame()\n",
        "df_Predictions = buildAndRunKNNModels_results(df_Predictions, 'Methodology', X_train, y_train, X_test, y_test)\n",
        "print(df_Predictions)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCYW-bRWqZk4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#Run KNN Model\n",
        "print (\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Predictions = buildAndRunKNNModels_results(df_Predictions, \"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time))\n",
        "print ('-'*60 )\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv0_YOjabiNB"
      },
      "outputs": [],
      "source": [
        "df_Results_2=df_Results.copy()\n",
        "df_Results_2_filtered = df_Results_2[df_Results_2['threshold'] <= 1.0]\n",
        "df_Results_2_filtered_sorted = df_Results_2_filtered.sort_values('Accuracy', ascending=False)\n",
        "df_Results_2_filtered_sorted\n",
        "df_Results_2_filtered_sorted.to_csv('hello.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DTj9WL4fHLk"
      },
      "outputs": [],
      "source": [
        "print(\"Time Taken by Model: --- %s seconds ---\"% (time.time() - start_time_now))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXX4eQsQo7q0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define flierprops\n",
        "flierprops = dict(marker='x', markerfacecolor='red', markersize=6, linestyle='none')\n",
        "\n",
        "# Iterate over the range\n",
        "for i in range(10):\n",
        "    sns.boxplot(x=y_train_cv, y=X_train_cv.columns[i], data=df, flierprops=flierprops)\n",
        "    plt.title(f'Boxplot of {df.columns[i]} by y')\n",
        "    plt.xlabel('y')\n",
        "    plt.ylabel(df.columns[i])\n",
        "    plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz3CQuvkkFfZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def buildAndRunRandomForestModels(df_Results, Methodology, X_train, y_train, X_test, y_test):\n",
        "    RF_model = RandomForestClassifier(n_estimators=100, bootstrap=True, max_features='sqrt', random_state=42)\n",
        "    RF_model.fit(X_train, y_train)\n",
        "    RF_test_score = RF_model.score(X_test, y_test)\n",
        "    rf_predictions = RF_model.predict(X_test)\n",
        "\n",
        "    print('Model Accuracy: {0}'.format(RF_test_score))\n",
        "    print(\"Confusion Matrix\")\n",
        "    Plot_confusion_matrix(y_test, rf_predictions)\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(y_test, rf_predictions))\n",
        "\n",
        "    rf_probs = RF_model.predict_proba(X_test)[:, 1]\n",
        "    roc_value = roc_auc_score(y_test, rf_probs)\n",
        "\n",
        "    print(\"Random Forest roc_value: {0}\".format(roc_value))\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, rf_probs)\n",
        "    threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "    print(\"Random Forest threshold: {0}\".format(threshold))\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    print(\"ROC for the test dataset\", '{:.1%}'.format(roc_auc))\n",
        "    plt.plot(fpr, tpr, label=\"Test, auc=\" + str(roc_auc))\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "\n",
        "    # Define empty DataFrame for predictions\n",
        "    df_predictions = pd.DataFrame()\n",
        "\n",
        "    # Append predictions to df_predictions DataFrame\n",
        "    predictions_df = pd.DataFrame({'Predicted': rf_predictions})\n",
        "    df_predictions = pd.concat([df_predictions, predictions_df], ignore_index=True)\n",
        "\n",
        "    new_row = pd.DataFrame({'Methodology': Methodology,\n",
        "                            'Model': 'Random Forest',\n",
        "                            'Accuracy': RF_test_score, 'roc_value': roc_value,\n",
        "                            'threshold': threshold}, index=[0])\n",
        "\n",
        "    df_Results = pd.concat([df_Results, new_row], ignore_index=True)\n",
        "\n",
        "    return df_predictions\n",
        "\n",
        "\n",
        "df_predictions = buildAndRunRandomForestModels(df_Results, 'Methodology', X_train_cv, y_train_cv, X_test_cv, y_test_cv)\n",
        "print(df_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "popRuOKZnejR"
      },
      "outputs": [],
      "source": [
        "df_predictions=df_predictions.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw-Obm7zliyS"
      },
      "outputs": [],
      "source": [
        "X_test_cv_2=X_test_cv.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5lZQhwmpx9C"
      },
      "outputs": [],
      "source": [
        "X_test_cv_2['Class']=df_predictions.values\n",
        "X_test_cv_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr3pTOXTDj3F"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from re import sub\n",
        "\n",
        "normal_records = X_test_cv_2.Class == 0\n",
        "fraud_records = X_test_cv_2.Class == 1\n",
        "\n",
        "plt.figure(figsize=(20, 60))\n",
        "for n, col in enumerate(cols):\n",
        "    plt.subplot(10, 3, n+1)\n",
        "    sns.distplot(X_test_cv_2[col][normal_records], color='green')\n",
        "    sns.distplot(X_test_cv_2[col][fraud_records], color='red')\n",
        "    plt.title(col, fontsize=17)\n",
        "\n",
        "    # Set legend\n",
        "    plt.legend(labels=['Normal', 'Fraud'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D39HKlSVIkg"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define flierprops\n",
        "flierprops = dict(marker='x', markerfacecolor='red', markersize=6, linestyle='none')\n",
        "\n",
        "# Iterate over the range\n",
        "for i in range(10):\n",
        "    sns.boxplot(x=X_test_cv_2['Class'], y=X_test_cv_2.columns[i], data=X_test_cv_2, flierprops=flierprops)\n",
        "    plt.title(f'Boxplot of {df.columns[i]} by y')\n",
        "    plt.xlabel('y')\n",
        "    plt.ylabel(df.columns[i])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jXBas9dnXF2"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_test_scaled = scaler.fit_transform(X_test_cv)\n",
        "\n",
        "pca_2 = PCA(n_components=2)\n",
        "X_test_pca_2_fitted = pca_2.fit_transform(X_test_scaled)\n",
        "X_test_pca_2 = pca_2.transform(X_test_scaled)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_test_pca_2[:, 0], X_test_pca_2[:, 1], marker='x', c=df_predictions.values, cmap='viridis', alpha=0.5)\n",
        "plt.title('Feature Space with 2 Principal Components')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar(label='Class (y)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0Y3DRa0ndAn"
      },
      "outputs": [],
      "source": [
        "df_pca_2 = pd.DataFrame(X_test_pca_2, columns=['PC1', 'PC2'])\n",
        "df_pca_2['y'] = df_predictions.values\n",
        "\n",
        "plt.figure(figsize=(4, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x='y', y='PC1', data=df_pca_2, flierprops={\"marker\": \"x\"})\n",
        "plt.title('PC1 by Class')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='y', y='PC2', data=df_pca_2, flierprops={\"marker\": \"x\"})\n",
        "plt.title('PC2 by Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AmNCTApP4zY"
      },
      "outputs": [],
      "source": [
        "df_Results_2_filtered_sorted"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
